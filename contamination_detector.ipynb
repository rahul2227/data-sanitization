{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Contamination Detector Module MVP\n",
    "\n",
    "I have tried detecting potentially contaminated segments in our training data.\n",
    "\n",
    "According to the seminar and project scope we have performed two main scopoes.\n",
    "1. **Reference Benchmark Comparison:** Each segment is compared against a reference set (synthetic here) via semantic similarity.\n",
    "2. **PaCoST-Inspired Confidence Testing:** For each segment, we generate a perturbed variant and compute model confidence (via perplexity) using a lightweight LM. A significant gap in confidence (lower perplexity on the original) indicates possible memorization or contamination."
   ],
   "id": "585bbb7c122e7d87"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-25T11:36:12.812273Z",
     "start_time": "2025-03-25T11:36:09.904991Z"
    }
   },
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# For timing and progress display\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading the preprocessed data",
   "id": "fa10e56af18cb385"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T11:40:34.533555Z",
     "start_time": "2025-03-25T11:36:12.815922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_file = os.path.join(\"data\", \"preprocessed_wikitext103_subset.csv\")\n",
    "df = pd.read_csv(data_file, on_bad_lines='skip', engine='python')\n",
    "print(\"Loaded data shape:\", df.shape)\n",
    "print(\"Sample rows:\")\n",
    "print(df.head())"
   ],
   "id": "423e8cebf3d404b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (186070, 5)\n",
      "Sample rows:\n",
      "                                                text  text_length  \\\n",
      "0  = Valkyria Chronicles III =\\nSenjō no Valkyria...        20297   \n",
      "1  = Valkyria Chronicles III =\\nSenjō no Valkyria...        20297   \n",
      "2  = Valkyria Chronicles III =\\nSenjō no Valkyria...        20297   \n",
      "3  = Valkyria Chronicles III =\\nSenjō no Valkyria...        20297   \n",
      "4  = Valkyria Chronicles III =\\nSenjō no Valkyria...        20297   \n",
      "\n",
      "                                        cleaned_text  \\\n",
      "0  = valkyria chronicles iii = senj no valkyria 3...   \n",
      "1  = valkyria chronicles iii = senj no valkyria 3...   \n",
      "2  = valkyria chronicles iii = senj no valkyria 3...   \n",
      "3  = valkyria chronicles iii = senj no valkyria 3...   \n",
      "4  = valkyria chronicles iii = senj no valkyria 3...   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  ['=', 'val', '##ky', '##ria', 'chronicles', 'i...   \n",
      "1  ['=', 'val', '##ky', '##ria', 'chronicles', 'i...   \n",
      "2  ['=', 'val', '##ky', '##ria', 'chronicles', 'i...   \n",
      "3  ['=', 'val', '##ky', '##ria', 'chronicles', 'i...   \n",
      "4  ['=', 'val', '##ky', '##ria', 'chronicles', 'i...   \n",
      "\n",
      "                                            segments  \n",
      "0  = valkyria chronicles iii = senj no valkyria 3...  \n",
      "1  valkyria of the battlefield 3), commonly refer...  \n",
      "2  released in january 2011 in japan, it is the t...  \n",
      "3  employing the same fusion of tactical and real...  \n",
      "4  the game began development in 2010, carrying o...  \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load/Define Reference Benchmark Data\n",
    "For now, I am defining a small reference set, later I plan to add texts from projectGutenberg or alike."
   ],
   "id": "2668d4633411179b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T11:40:38.519650Z",
     "start_time": "2025-03-25T11:40:34.771531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reference_texts = [\n",
    "    \"this is a known contaminated text from benchmark dataset\",\n",
    "    \"another reference text that should not be in the training data\",\n",
    "    \"benchmark evaluation text that must remain separate\"\n",
    "]\n",
    "\n",
    "# Load a SentenceTransformer model for computing embeddings\n",
    "ref_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Compute embeddings for the reference texts\n",
    "ref_embeddings = ref_model.encode(reference_texts, convert_to_tensor=True)"
   ],
   "id": "e84dbd7cb6523646",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Functions for reference comparison\n",
    "\n",
    "a function that computes maximum cosine similarity between a given segment and the reference texts. If the similarity exceeds a threshold (e.g., 0.9), we flag the segment as potentially contaminated by reference overlap."
   ],
   "id": "6d0e68561901f9ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T11:40:38.592862Z",
     "start_time": "2025-03-25T11:40:38.591264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_reference_similarity(segment, ref_embeddings, threshold=0.9):\n",
    "    # Compute embedding for the segment\n",
    "    segment_embedding = ref_model.encode(segment, convert_to_tensor=True)\n",
    "    # Compute cosine similarities with each reference embedding\n",
    "    cos_scores = util.cos_sim(segment_embedding, ref_embeddings)\n",
    "    max_sim = cos_scores.max().item()\n",
    "    flag = max_sim >= threshold\n",
    "    return max_sim, flag"
   ],
   "id": "ff8ca1854c0479d3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Confidence Testing(PaCoST-Inspired)\n",
    "\n",
    "**Perturbation Function:** We define a simple perturbation function that shuffles the words in the segment. (In practice, you might use more advanced paraphrasing techniques.)\n",
    "\n",
    "**Perplexity Calculation:** We use a lightweight LM (DistilGPT-2) to compute the perplexity of a text. Lower perplexity indicates higher confidence.\n",
    "\n",
    "**Note:** Perplexity is computed as the exponential of the loss from the model. I have used small batch size for avoiding memory issues as most of the code is working locally.\n"
   ],
   "id": "d2509bff2fd3d3e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T11:40:39.073813Z",
     "start_time": "2025-03-25T11:40:38.596963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def perturb_text(text):\n",
    "    words = text.split()\n",
    "    if len(words) <= 1:\n",
    "        return text  # No perturbation possible for single-word texts\n",
    "    random.shuffle(words)\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Load a lightweight LM for perplexity calculation\n",
    "lm_model_name = \"distilgpt2\"  # a lightweight model\n",
    "lm_model = AutoModelForCausalLM.from_pretrained(lm_model_name)\n",
    "lm_tokenizer = AutoTokenizer.from_pretrained(lm_model_name)\n",
    "lm_model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    lm_model.to(\"cuda\")\n",
    "\n",
    "def compute_perplexity(text, model, tokenizer):\n",
    "    # Encode the text and compute loss (per-token)\n",
    "    encodings = tokenizer(text, return_tensors='pt')\n",
    "    if torch.cuda.is_available():\n",
    "        encodings = {k: v.to(\"cuda\") for k, v in encodings.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings, labels=encodings[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "    perplexity = torch.exp(loss)\n",
    "    return perplexity.item()"
   ],
   "id": "5b333f71e32210c8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Contamination detection on a Batch of Segments\n",
    "\n",
    "processing the data in batches:\n",
    "1. Check reference similarity\n",
    "2. Compute perplexity for the original segment.\n",
    "3. Generate a perturbed version and compute its perplexity.\n",
    "4. Flag the segment if:\n",
    "    - The max reference similarity is above a threshold (0.8), OR\n",
    "    - The original perplexity is significantly lower than the perturbed perplexity\n",
    "- **Simple Ration Test:** if perplexity(original) < 0.8 * perplexity(perturbed), I flag it."
   ],
   "id": "52bd1552ae46a3ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T11:40:39.103082Z",
     "start_time": "2025-03-25T11:40:39.091418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_df = df.sample(n=1000, random_state=42).copy()\n",
    "\n",
    "# lists to hold the results\n",
    "ref_similarities = []\n",
    "ref_flags = []\n",
    "perplexity_orig_list = []\n",
    "perplexity_perturbed_list = []\n",
    "confidence_flags = []\n",
    "\n",
    "# threshold for perplexity ratio\n",
    "perplexity_ratio_threshold = 0.8"
   ],
   "id": "dc163d5de566d167",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T11:41:28.352195Z",
     "start_time": "2025-03-25T11:40:39.122836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process each segment in the sample\n",
    "for seg in tqdm(sample_df['segments'].tolist(), desc=\"Processing segments\"):\n",
    "    # Reference similarity check\n",
    "    max_sim, ref_flag = check_reference_similarity(seg, ref_embeddings, threshold=0.9)\n",
    "    ref_similarities.append(max_sim)\n",
    "    ref_flags.append(ref_flag)\n",
    "\n",
    "    # Compute perplexity for original\n",
    "    try:\n",
    "        ppl_orig = compute_perplexity(seg, lm_model, lm_tokenizer)\n",
    "    except Exception as e:\n",
    "        ppl_orig = None\n",
    "    # Generate perturbed version and compute perplexity\n",
    "    perturbed_seg = perturb_text(seg)\n",
    "    try:\n",
    "        ppl_perturbed = compute_perplexity(perturbed_seg, lm_model, lm_tokenizer)\n",
    "    except Exception as e:\n",
    "        ppl_perturbed = None\n",
    "\n",
    "    perplexity_orig_list.append(ppl_orig)\n",
    "    perplexity_perturbed_list.append(ppl_perturbed)\n",
    "\n",
    "    # Check if confidence gap flag condition is met (if both perplexities are computed)\n",
    "    if (ppl_orig is not None and ppl_perturbed is not None and ppl_perturbed > 0):\n",
    "        conf_flag = ppl_orig < perplexity_ratio_threshold * ppl_perturbed\n",
    "    else:\n",
    "        conf_flag = False\n",
    "    confidence_flags.append(conf_flag)\n",
    "\n",
    "# Add the results to the sample DataFrame\n",
    "sample_df['ref_similarity'] = ref_similarities\n",
    "sample_df['ref_flag'] = ref_flags\n",
    "sample_df['ppl_original'] = perplexity_orig_list\n",
    "sample_df['ppl_perturbed'] = perplexity_perturbed_list\n",
    "sample_df['confidence_flag'] = confidence_flags\n",
    "\n",
    "# Combine flags: flag if either reference flag or confidence flag is True\n",
    "sample_df['contamination_flag'] = sample_df['ref_flag'] | sample_df['confidence_flag']"
   ],
   "id": "c3c5dd1ef3b33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing segments:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5797101c0acc47b3a2ad004f9c0f208e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T11:46:50.076186Z",
     "start_time": "2025-03-25T11:46:50.067453Z"
    }
   },
   "cell_type": "code",
   "source": "sample_df.head()",
   "id": "3a1653bc59e16a35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     text  text_length  \\\n",
       "151849  = William Wilberforce =\\nWilliam Wilberforce (...        51825   \n",
       "31078   = Roger Federer =\\nRoger Federer (German: [ˈfe...        56964   \n",
       "120548  = USS Yancey (AKA-93) =\\nUSS Yancey (AKA-93 / ...        20321   \n",
       "117870  = Alberta and Great Waterways Railway scandal ...        28416   \n",
       "44726   = Gregory Helms =\\nGregory Shane Helms (born J...        24202   \n",
       "\n",
       "                                             cleaned_text  \\\n",
       "151849  = william wilberforce = william wilberforce (2...   \n",
       "31078   = roger federer = roger federer (german: [ fe ...   \n",
       "120548  = uss yancey (aka-93) = uss yancey (aka-93 / l...   \n",
       "117870  = alberta and great waterways railway scandal ...   \n",
       "44726   = gregory helms = gregory shane helms (born ju...   \n",
       "\n",
       "                                                   tokens  \\\n",
       "151849  ['=', 'william', 'wil', '##ber', '##force', '=...   \n",
       "31078   ['=', 'roger', 'federer', '=', 'roger', 'feder...   \n",
       "120548  ['=', 'uss', 'yan', '##cey', '(', 'aka', '-', ...   \n",
       "117870  ['=', 'alberta', 'and', 'great', 'waterways', ...   \n",
       "44726   ['=', 'gregory', 'helm', '##s', '=', 'gregory'...   \n",
       "\n",
       "                                                 segments  ref_similarity  \\\n",
       "151849  wilberforce's house in old palace yard became ...       -0.010654   \n",
       "31078   = = = federer vs. agassi = = = federer and aga...        0.133301   \n",
       "120548  yancey entered tokyo bay on the morning of 2 s...        0.030656   \n",
       "117870  guarantees to the so-called \"a & gw\" were more...        0.034958   \n",
       "44726   helms and storm got a shot at the wcw tag team...        0.133794   \n",
       "\n",
       "        ref_flag  ppl_original  ppl_perturbed  confidence_flag  \\\n",
       "151849     False    240.796692    4236.520996             True   \n",
       "31078      False     83.830208     841.818359             True   \n",
       "120548     False    174.029938    1052.760254             True   \n",
       "117870     False     82.243286    1485.180176             True   \n",
       "44726      False    365.937317    1935.085693             True   \n",
       "\n",
       "        contamination_flag  \n",
       "151849                True  \n",
       "31078                 True  \n",
       "120548                True  \n",
       "117870                True  \n",
       "44726                 True  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>segments</th>\n",
       "      <th>ref_similarity</th>\n",
       "      <th>ref_flag</th>\n",
       "      <th>ppl_original</th>\n",
       "      <th>ppl_perturbed</th>\n",
       "      <th>confidence_flag</th>\n",
       "      <th>contamination_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151849</th>\n",
       "      <td>= William Wilberforce =\\nWilliam Wilberforce (...</td>\n",
       "      <td>51825</td>\n",
       "      <td>= william wilberforce = william wilberforce (2...</td>\n",
       "      <td>['=', 'william', 'wil', '##ber', '##force', '=...</td>\n",
       "      <td>wilberforce's house in old palace yard became ...</td>\n",
       "      <td>-0.010654</td>\n",
       "      <td>False</td>\n",
       "      <td>240.796692</td>\n",
       "      <td>4236.520996</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31078</th>\n",
       "      <td>= Roger Federer =\\nRoger Federer (German: [ˈfe...</td>\n",
       "      <td>56964</td>\n",
       "      <td>= roger federer = roger federer (german: [ fe ...</td>\n",
       "      <td>['=', 'roger', 'federer', '=', 'roger', 'feder...</td>\n",
       "      <td>= = = federer vs. agassi = = = federer and aga...</td>\n",
       "      <td>0.133301</td>\n",
       "      <td>False</td>\n",
       "      <td>83.830208</td>\n",
       "      <td>841.818359</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120548</th>\n",
       "      <td>= USS Yancey (AKA-93) =\\nUSS Yancey (AKA-93 / ...</td>\n",
       "      <td>20321</td>\n",
       "      <td>= uss yancey (aka-93) = uss yancey (aka-93 / l...</td>\n",
       "      <td>['=', 'uss', 'yan', '##cey', '(', 'aka', '-', ...</td>\n",
       "      <td>yancey entered tokyo bay on the morning of 2 s...</td>\n",
       "      <td>0.030656</td>\n",
       "      <td>False</td>\n",
       "      <td>174.029938</td>\n",
       "      <td>1052.760254</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117870</th>\n",
       "      <td>= Alberta and Great Waterways Railway scandal ...</td>\n",
       "      <td>28416</td>\n",
       "      <td>= alberta and great waterways railway scandal ...</td>\n",
       "      <td>['=', 'alberta', 'and', 'great', 'waterways', ...</td>\n",
       "      <td>guarantees to the so-called \"a &amp; gw\" were more...</td>\n",
       "      <td>0.034958</td>\n",
       "      <td>False</td>\n",
       "      <td>82.243286</td>\n",
       "      <td>1485.180176</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44726</th>\n",
       "      <td>= Gregory Helms =\\nGregory Shane Helms (born J...</td>\n",
       "      <td>24202</td>\n",
       "      <td>= gregory helms = gregory shane helms (born ju...</td>\n",
       "      <td>['=', 'gregory', 'helm', '##s', '=', 'gregory'...</td>\n",
       "      <td>helms and storm got a shot at the wcw tag team...</td>\n",
       "      <td>0.133794</td>\n",
       "      <td>False</td>\n",
       "      <td>365.937317</td>\n",
       "      <td>1935.085693</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Saving Flagged segments\n",
    "\n",
    "summary stats and saving the flagged segments"
   ],
   "id": "21115a665fd1fe7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T11:45:04.473859Z",
     "start_time": "2025-03-25T11:45:03.690355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count the number of flagged segments\n",
    "num_flagged = sample_df['contamination_flag'].sum()\n",
    "print(f\"Number of flagged segments in the sample: {num_flagged} / {len(sample_df)}\")\n",
    "\n",
    "# Save the results for further inspection\n",
    "output_dir = \"data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "flagged_output_file = os.path.join(output_dir, \"contamination_flags_sample.csv\")\n",
    "sample_df.to_csv(flagged_output_file, index=False)\n",
    "print(f\"Flagged segments saved to {flagged_output_file}\")"
   ],
   "id": "11ed6388f4fdabb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flagged segments in the sample: 988 / 1000\n",
      "Flagged segments saved to data/contamination_flags_sample.csv\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aa8c9e8b1c5a4fcf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
